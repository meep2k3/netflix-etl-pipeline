# Netflix ETL Pipeline with Airflow, MySQL, and Superset

![Airflow](https://img.shields.io/badge/Airflow-2.10-blue)
![MySQL](https://img.shields.io/badge/MySQL-8.0-orange)
![Superset](https://img.shields.io/badge/Apache%20Superset-2.1-brightgreen)
![Docker](https://img.shields.io/badge/Docker-Compose-blue)

## ğŸ“Œ Introduction
This project implements an **ETL pipeline** to process the **Netflix Movies & TV Shows dataset**.  
The goal is to automate data extraction, transformation, loading into a **star schema** in MySQL, and visualize insights with Superset.  

Key technologies used:
- **Apache Airflow** â€“ Workflow orchestration  
- **MySQL** â€“ Data warehouse  
- **Docker Compose** â€“ Containerized deployment  
- **Apache Superset** â€“ Dashboard & visualization  

---

## âš™ï¸ System Architecture
- **Airflow** â†’ Orchestrates and manages ETL tasks  
- **MySQL** â†’ Stores processed data in a star schema  
- **Docker** â†’ Ensures reproducible and isolated environments  
- **Superset** â†’ Provides interactive dashboards  

### Pipeline Workflow
1. **Extract** â†’ Load raw CSV (`netflix_titles.csv`) from `data/raw/`  
2. **Transform** â†’ Clean & normalize into a star schema format  
3. **Load** â†’ Insert transformed data into MySQL database  
4. **Visualize** â†’ Explore insights with Superset dashboards  

---

## ğŸ¯ Learning Objectives
This project was built to practice **Data Engineering skills**:
- Building ETL pipelines with Python & SQL  
- Workflow orchestration with Apache Airflow  
- Containerization with Docker Compose  
- Designing star schema data models in MySQL  
- Data visualization with Apache Superset  

---

## ğŸ“‚ Project Structure
```
netflix-etl-pipeline/
â”œâ”€â”€ docker-compose.yml          # Docker services (Airflow, MySQL, Superset, Redis, Flower)
â”œâ”€â”€ .env                        # Environment variables
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ Dockerfile.airflow          # Custom Airflow image
â”œâ”€â”€ Dockerfile.superset         # Custom Superset image
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/                   # ETL DAGs
â”‚   â”‚   â”œâ”€â”€ netflix_etl_dag.py
â”‚   â”‚   â””â”€â”€ setup_connections.py
â”‚   â”œâ”€â”€ logs/                   # Airflow logs
â”‚   â””â”€â”€ plugins/                # (optional custom operators/hooks)
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ airflow.cfg
â”‚   â””â”€â”€ superset/superset_config.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ netflix_titles.csv  # Raw dataset
â”‚   â””â”€â”€ processed/              # Transformed CSVs for loading
â””â”€â”€ dashboards/
    â””â”€â”€ netflix_superset.json   # Exported Superset dashboard
```

---

## ğŸš€ How to Run

1. **Clone the repository**
   ```bash
   git clone https://github.com/<your-username>/netflix-etl-pipeline.git
   cd netflix-etl-pipeline
   ```

2. **Start all services**
   ```bash
   docker compose up -d --build
   ```
   This will start:  
   - Airflow (webserver, scheduler, worker, Redis, Flower, Postgres metadata DB)  
   - MySQL (data warehouse)  
   - Superset (visualization)  

3. **Initialize Airflow**
   ```bash
   docker exec -it airflow-webserver bash
   bash init_airflow.sh
   ```

4. **Initialize Superset**
   ```bash
   docker exec -it superset bash
   bash init_superset.sh
   ```

5. **Access the services**
   - Airflow â†’ [http://localhost:8080](http://localhost:8080)  
   - Superset â†’ [http://localhost:8088](http://localhost:8088)  
   - MySQL â†’  
     ```bash
     mysql -h localhost -P 3306 -u netflix_user -p
     ```

---

## âœ… Quick Test
1. Open Airflow UI â†’ Trigger DAG `netflix_etl_dag`  
2. Check MySQL â†’ Tables should be loaded into `netflix_db`  
3. Open Superset UI â†’ Explore dashboard  

---

## ğŸ“Š Pipeline Diagram
```mermaid
flowchart LR
    A[Raw CSV: netflix_titles.csv] -->|Extract| B[Airflow DAG]
    B -->|Transform| C[Processed CSVs]
    C -->|Load| D[MySQL Database: Star Schema]
    D -->|Query| E[Superset Dashboard]
```

---

## ğŸ“Š Dashboards Preview
- **Content Growth Over Time**  
  ![Growth](dashbroads/content-growth-over-time-2025-09-07T17-29-34.974Z.jpg)

- **Distribution by Type**  
  ![Type](dashbroads/content-distribution-by-type-2025-09-07T17-29-44.282Z.jpg)

- **Top 15 Countries**  
  ![Countries](dashbroads/top-15-countries-by-content-volume-2025-09-07T17-29-53.079Z.jpg)

- **Ratings Distribution**  
  ![Ratings](dashbroads/content-ratings-distribution-2025-09-07T17-30-00.744Z.jpg)

- **Top Genres**  
  ![Genres](dashbroads/top-genres-performance-2025-09-07T17-30-06.903Z.jpg)

- **Duration & Seasons**  
  ![Duration](dashbroads/content-duration-and-season-analysis-2025-09-07T17-30-13.328Z.jpg)

- **Full Dashboard**  
  ![Dashboard](dashbroads/netflix-analytics-dashboard-2025-09-07T17-30-26.572Z.jpg)

---

## ğŸ”® Future Improvements
- Support **incremental load** instead of full refresh  
- Add **data quality checks** with Great Expectations  
- Build a **recommendation engine**  
- Enable **Superset authentication** (OAuth/LDAP)  

---

## ğŸ“š Dataset
- Source: [Netflix Movies & TV Shows](https://www.kaggle.com/shivamb/netflix-shows)  

---

## ğŸ‘¨â€ğŸ’» Author
- [meep2k3](https://github.com/meep2k3)

## ğŸ“œ License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
